 # AMZN Stock Forecasting with Airflow and HGBR

## ğŸ“Œ Project Overview
This project automates stock price prediction for **Amazon (AMZN)** using **Apache Airflow**, **Docker**, and **HistGradientBoostingRegressor (HGBR)**. The pipeline:
- Retrieves stock data from the **Alpha Vantage API**.
- Computes **technical indicators** (SMA, RSI, volatility, OBV).
- Trains an ML model with **HGBR and hyperparameter tuning**.
- Predicts stock prices and evaluates model performance.
- Generates a **visual comparison** of actual vs. predicted prices with key metrics (**RÂ², MSE, MAE**).

The workflow is fully **containerized using Docker**, ensuring **scalability, reproducibility, and easy deployment**.

---

## ğŸ“Œ Data Source: Alpha Vantage API
The pipeline fetches **daily stock price data** from [Alpha Vantage API](https://www.alphavantage.co/documentation/) using the `TIME_SERIES_DAILY` function.

### **Example API Request**
```bash
https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=AMZN&apikey=YOUR_API_KEY&outputsize=full&datatype=json
```
**Extracted Features:**
- **Market data:** `open`, `high`, `low`, `close`, `volume`
- **Computed indicators:** `SMA (7 & 14 days)`, `volatility`, `RSI`, `OBV`

To use the API, obtain a **free API key** from [Alpha Vantage](https://www.alphavantage.co/support/#api-key).

---

## ğŸ“Œ Project Structure
```
â”œâ”€â”€ dags/                          # Airflow DAGs
â”‚   â”œâ”€â”€ amzn_forecast_pipeline.py  # DAG definition
â”œâ”€â”€ data/                          # Data storage
â”‚   â”œâ”€â”€ extracted_data.csv         # Raw stock data
â”‚   â”œâ”€â”€ processed_data.csv         # Preprocessed dataset
â”‚   â”œâ”€â”€ predictions.csv            # Stock price predictions
â”‚   â”œâ”€â”€ model_metrics.csv          # Performance metrics (RÂ², MSE, MAE)
â”‚   â”œâ”€â”€ plots/                     # Visualization output
â”‚   â”‚   â”œâ”€â”€ amzn_predictions.png   # Actual vs. predicted prices
â”œâ”€â”€ models/                        # Trained ML models
â”‚   â”œâ”€â”€ amzn_model.pkl             # Saved model
â”œâ”€â”€ scripts/                       # Python scripts
â”‚   â”œâ”€â”€ extract_data.py            # Fetches AMZN stock data
â”‚   â”œâ”€â”€ preprocess_data.py         # Processes stock data
â”‚   â”œâ”€â”€ train_model.py             # Trains HGBR model
â”‚   â”œâ”€â”€ predict.py                 # Generates predictions
â”‚   â”œâ”€â”€ visualize_predictions.py   # Plots results
â”œâ”€â”€ docker-compose.yaml            # Docker setup
â”œâ”€â”€ requirements.txt               # Dependencies
â””â”€â”€ README.md                      # Documentation
```

---

## ğŸ“Œ Pipeline Workflow
This **end-to-end ML pipeline** runs in **Apache Airflow**:

1ï¸âƒ£ **Extract Data** â†’ Fetch AMZN stock data (`extract_data.py`).  
2ï¸âƒ£ **Preprocess Data** â†’ Clean data, compute indicators (`preprocess_data.py`).  
3ï¸âƒ£ **Train Model** â†’ Train HGBR with hyperparameter tuning (`train_model.py`).  
4ï¸âƒ£ **Make Predictions** â†’ Predict stock prices (`predict.py`).  
5ï¸âƒ£ **Visualize Results** â†’ Generate plots and model evaluation (`visualize_predictions.py`).  

Airflow DAG execution order:
```
extract_data >> preprocess_data >> train_model >> predict >> visualize_predictions
```

---

## ğŸ“Œ Setup and Execution Guide

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/FranRguezCer/amzn-stocks-predictions-airflow.git
cd amzn-stock-forecast
```

### 2ï¸âƒ£ Set Up Docker and Airflow
Ensure **Docker** and **Docker Compose** are installed. Then, start the Airflow containers:
```bash
docker-compose up -d  # Start Airflow services
```

### 3ï¸âƒ£ Access Airflow Web UI
Once running, open:
```
http://localhost:8080
```
- **DAG Name:** `amzn_forecast_pipeline`
- Enable the DAG and trigger a **manual run**.

### 4ï¸âƒ£ View Results
Once the DAG completes:
- **Predictions:** `data/predictions.csv`
- **Model Metrics:** `data/model_metrics.csv`
- **Visualization:** `data/plots/amzn_predictions.png`

---

## ğŸ“Œ Model Performance Evaluation
Evaluated on **20% test data**, key metrics include:
- **RÂ² Score**: Accuracy of predictions.
- **MSE (Mean Squared Error)**: Error magnitude.
- **MAE (Mean Absolute Error)**: Average deviation.

Metrics are **displayed on the visualization**, centered at the top.

---

## ğŸ“Œ Dependency Management with Docker
You **do not need to install dependencies manually**. Docker Compose installs them inside the container:

```yaml
airflow_worker:
  container_name: airflow_worker
  <<: *airflow-common
  command: celery worker
  restart: always
  depends_on:
    airflow_init:
      condition: service_completed_successfully
  entrypoint: >
    sh -c "pip install -r /opt/airflow/requirements.txt && exec airflow celery worker"
```

### âŒ No Need for Manual Installation
Do **not** run:
```bash
pip install -r requirements.txt
```
This is already handled inside the Docker container.

### âš ï¸ When to Install Manually?
Only if:
- Running scripts **outside Docker**.
- Adding a new library **without restarting containers**.

Manual install:
```bash
pip install -r requirements.txt
```

### ğŸš€ Conclusion
With Docker Compose, dependencies are fully managed **inside the container**. To start the project:
```bash
docker-compose up -d
```

ğŸ”¹ **Your Airflow pipeline is fully functional inside the Docker environment!** ğŸš€

---

## ğŸ“Œ Example Visualization Output
The pipeline generates a **comparison plot**:

![AMZN Stock Prediction](data/plots/amzn_predictions.png)

Metrics **(RÂ², MSE, MAE)** are displayed at the top.

---

## ğŸ“Œ Future Improvements
ğŸš€ **Next steps:**
- Optimize hyperparameters using **Bayesian Search**.
- Add more **market indicators** (e.g., Bollinger Bands).
- Implement **LSTM/Transformer models** for better forecasting.

---

## ğŸ“Œ License
This project is open-source under the **MIT License**.

---

**Author:** Francisco JosÃ© RodrÃ­guez Cerezo  
ğŸ“§ Contact: [portfolio.fjrguezcer@gmail.com](mailto:portfolio.fjrguezcer@gmail.com)  
ğŸ‘‰ GitHub: [FranRguezCer](https://github.com/FranRguezCer/)
